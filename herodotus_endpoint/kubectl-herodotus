#!/usr/bin/python3

import argparse
import json
import re
import shutil
import subprocess
import sys

from typing import Dict
from urllib.error import HTTPError
from urllib.request import urlopen


OPTION_NODE = "node"
OPTION_POD = "pod"

# hardcoded from scheduler binary
PLUGIN_FAILED = 0
PLUGIN_PASSED = 1
PLUGIN_SKIPPED = 2

# for making output look nice and aligned
TEXT_BUFFER = 5

def err(msg: str):
    print(msg, file=sys.stderr)
    exit(-1)

def get_endpoint_port() -> int:
    kubectl_cmd = f"{shutil.which('kubectl')} get service herodotus-endpoint -n kube-system"
    kubectl_get = subprocess.run(kubectl_cmd.split(), capture_output=True).stdout.decode()
    port_search = re.search(r'8000:(\d+)/TCP', kubectl_get)
    
    if not port_search:
        err("Failed to get herodotus-endpoint port. Is the service running on the cluster?")

    return int(port_search.group(1))

def get_data_from_endpoint(request_url: str) -> Dict:
    try: 
        r = urlopen(request_url)
        return json.loads(r.read().decode())
    except HTTPError as e:
        err(f"Error contacting endpoint -> Received HTTP code {e.code}: {e.reason}")
    

def display_node_data(node_name: str, data: Dict):

    print(f"Node: {node_name}:")

    print("\tNode Eligibility:")
    print(f"\t\tEligibility Rate: {data['node_eligible_num']}/{data['node_eligible_check_num']} ({round(data['node_eligible_num']/data['node_eligible_check_num']*100)}%)")

    print("\n\tNode Scores:")
    print(f"\t\tTotal Accumulated Score:             {data['node_score_total']}")
    print(f"\t\tTotal Score Attempts:                {data['node_score_attempts']}")
    print(f"\t\tAverage Score per Schedule Cycle:    {round(data['node_score_total']/data['node_score_attempts'])}\n")

    node_filter_pass_pcts = {filterName: round(passNum/data['node_filter_attempts'][filterName]*100) for filterName, passNum in data['node_filter_pass'].items()}
    longest_filter_length = max(map(lambda x: len(x), data['node_filter_attempts'].keys()))
    longest_plugin_length = max(map(lambda x: len(x), data['node_score_plugin_total'].keys()))

    print(f"\n\t\tPlugin Breakdown:")

    # sort only by alphabet
    for plugin_name, plugin_score in sorted(data['node_score_plugin_total'].items(), key=lambda x: x[0]):
        num_buffer_spaces = longest_plugin_length-len(plugin_name) + TEXT_BUFFER
        print(f"\t\t\t{plugin_name}:{' '*num_buffer_spaces}{plugin_score}")
    
    print("\n\tNode Filter Pass Rate:")

    # sort by percentage by alphabet
    for filterName, pct in sorted(node_filter_pass_pcts.items(), key=lambda x: (x[1], x[0])):
        num_buffer_spaces = longest_filter_length-len(filterName) + TEXT_BUFFER
        print(f"\t\t{filterName}:{' '*num_buffer_spaces}{data['node_filter_pass'][filterName]}/{data['node_filter_attempts'][filterName]} ({pct}%)")

def display_pod_data(pod_name: str, namespace: str, data: Dict):
    nodes = sorted(data['filter_status'][pod_name].keys())
    print(f"Pod: {pod_name}")

    longest_score_filter_length = None

    all_filters_passed = set()
    choosen_node = None

    print("\tNode Filter Statuses:")
    for node in nodes:
        print(f"\t\tNode: {node}")
        failed_filters = []
        skipped_filters = []
        passed_filters = []

        for filter_name, filter_status in sorted(data['filter_status'][pod_name][node].items(), key=lambda x: x[0]):
            if filter_status == PLUGIN_FAILED:
                failed_filters.append(filter_name)
            elif filter_status == PLUGIN_SKIPPED:
                skipped_filters.append(filter_name)
            elif filter_status == PLUGIN_PASSED:
                passed_filters.append(filter_name)

        if len(failed_filters) == 0 and len(skipped_filters) == 0:
            print(f"\t\t\t...all filters passed!")
            all_filters_passed.add(node)
        else:
            print("\t\t\tFailed Filters:")
            if len(failed_filters) > 0:
                for failed_name in sorted(failed_filters):
                    print(f"\t\t\t\t- {failed_name}")
            else:
                print("\t\t\t\tNo filters failed!")

            print("\n\t\t\tSkipped Filters:")
            if len(skipped_filters) > 0:
                for skipped_filter in sorted(skipped_filters):
                    print(f"\t\t\t\t- {skipped_filter}")
            else:
                print("\t\t\t\tNo filters skipped!")

            print("\n\t\t\tPassed Filters:")
            if len(passed_filters) > 0:
                for passed_filter in sorted(passed_filters):
                    print(f"\t\t\t\t- {passed_filter}")
            else:
                print("\t\t\t\tNo filters passed!")
        print()

    print("\tNode Scoring Filters:")
    max_node_score = 0
    max_node = None
    choosen_reason = None
    for node in nodes:
        print(f"\t\tNode: {node}")
        if data['skipped_scoring']:
            # only one node eligible
            if node in all_filters_passed:
                print("\t\t\tscoring skipped... node choosen")
                choosen_node = node
                choosen_reason = "Only Valid Node"
            else:
                print("\t\t\tscoring skipped... node NOT choosen")
        else:
            # there exists multiple eligible nodes that have scores

            if node in data['filter_scores'][pod_name].keys():
                # get the longest scoring filter for proper text displacement
                if longest_score_filter_length is None:
                    longest_score_filter_length = max(map(lambda x: len(x), data['filter_scores'][pod_name][node].keys()))

                total_score = 0
                longest_score_chars = 0
                for filter_name, filter_score in sorted(data['filter_scores'][pod_name][node].items(), key=lambda x: x[0]):
                    num_buffer_spaces = longest_score_filter_length-len(filter_name) + TEXT_BUFFER
                    print(f"\t\t\t- {filter_name}:{' '*num_buffer_spaces}{filter_score}")
                    total_score += filter_score
                    longest_score_chars = max(longest_score_chars, len(str(filter_score)))

                if total_score > max_node_score:
                    max_node = node
                    max_node_score = total_score
                    choosen_reason = "Highest Score"

                print(f"\t\t{'-'*(longest_score_filter_length + TEXT_BUFFER + longest_score_chars + 16)}")
                print("\t\tTotal:" + " "*(longest_score_filter_length + 10) + f"{total_score}")
            else:
                # this particular node scoring was skipped
                print("\t\t\t- Scoring skipped because one or more filter(s) failed")

        print()

    if choosen_node is None:
        choosen_node = max_node

    print(f"\n\tPlaced node: {choosen_node}")
    print(f"\tReason:      {choosen_reason}")

            


def cli(options: argparse.Namespace):
    port = get_endpoint_port()
    base_endpoint_url = f"http://localhost:{port}/"

    if options.type == OPTION_NODE:
        data = get_data_from_endpoint(base_endpoint_url + f"node?name={options.name}")
        display_node_data(options.name, data)
    elif options.type == OPTION_POD:
        data = get_data_from_endpoint(base_endpoint_url + f"pod?name={options.name}&namespace={options.namespace}")
        display_pod_data(options.name, options.namespace, data)
    


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        prog="HerodotusEndpoint",
        description="Tool to view data from Herodotus scheduler"
    )

    parser.add_argument('type', choices=[OPTION_NODE, OPTION_POD], help="Choose whether to query data against a pod or a node")
    parser.add_argument('name', help="Name of the pod or node to query against")
    parser.add_argument('-n', '--namespace', required=False, default="default", help="Namespace of the pod if querying against pods")
    
    cli(parser.parse_args())